{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "\n",
    "---\n",
    "\n",
    "In this notebook, exploiting the analysis made in the previous notebook, we are going to preprocess the data to build training and testing datasets for the prediction model we need to construct to tackle the problem exposed in the current project.\n",
    "\n",
    "For that, working on the tabular data file *train_users_2.csv*, we will proceed into various steps, following the guidelines proposed in the previous notebook:\n",
    "* Gestion of the IDs\n",
    "* Gestion of the ages\n",
    "* Gestion of the missing values\n",
    "* Gestion of the dates\n",
    "* Gestion of the categorical features\n",
    "* Gestion of the continuous variables\n",
    "\n",
    "Thus, we will obtain a consistent and consolidated data file, necessary to construct the training and testing datasets.\n",
    "\n",
    "As always, the prerequisite step consists on loading the appropriate packages to perform our work:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activate 'airbnb' environment:\n",
    "!source activate airbnb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Needed packages:\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need, too, to load the tabular data file *train_users_2.csv*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Some basic info:\n",
      "'train_users_2' has 213451 data points with 16 variables each.\n",
      "'train_users_2' counts 218598 missing values.\n",
      "\n",
      "*** First lines:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date_account_created</th>\n",
       "      <th>timestamp_first_active</th>\n",
       "      <th>date_first_booking</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>signup_method</th>\n",
       "      <th>signup_flow</th>\n",
       "      <th>language</th>\n",
       "      <th>affiliate_channel</th>\n",
       "      <th>affiliate_provider</th>\n",
       "      <th>first_affiliate_tracked</th>\n",
       "      <th>signup_app</th>\n",
       "      <th>first_device_type</th>\n",
       "      <th>first_browser</th>\n",
       "      <th>country_destination</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gxn3p5htnn</td>\n",
       "      <td>2010-06-28</td>\n",
       "      <td>20090319043255</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-unknown-</td>\n",
       "      <td>NaN</td>\n",
       "      <td>facebook</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>direct</td>\n",
       "      <td>direct</td>\n",
       "      <td>untracked</td>\n",
       "      <td>Web</td>\n",
       "      <td>Mac Desktop</td>\n",
       "      <td>Chrome</td>\n",
       "      <td>NDF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>820tgsjxq7</td>\n",
       "      <td>2011-05-25</td>\n",
       "      <td>20090523174809</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MALE</td>\n",
       "      <td>38.0</td>\n",
       "      <td>facebook</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>seo</td>\n",
       "      <td>google</td>\n",
       "      <td>untracked</td>\n",
       "      <td>Web</td>\n",
       "      <td>Mac Desktop</td>\n",
       "      <td>Chrome</td>\n",
       "      <td>NDF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4ft3gnwmtx</td>\n",
       "      <td>2010-09-28</td>\n",
       "      <td>20090609231247</td>\n",
       "      <td>2010-08-02</td>\n",
       "      <td>FEMALE</td>\n",
       "      <td>56.0</td>\n",
       "      <td>basic</td>\n",
       "      <td>3</td>\n",
       "      <td>en</td>\n",
       "      <td>direct</td>\n",
       "      <td>direct</td>\n",
       "      <td>untracked</td>\n",
       "      <td>Web</td>\n",
       "      <td>Windows Desktop</td>\n",
       "      <td>IE</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bjjt8pjhuk</td>\n",
       "      <td>2011-12-05</td>\n",
       "      <td>20091031060129</td>\n",
       "      <td>2012-09-08</td>\n",
       "      <td>FEMALE</td>\n",
       "      <td>42.0</td>\n",
       "      <td>facebook</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>direct</td>\n",
       "      <td>direct</td>\n",
       "      <td>untracked</td>\n",
       "      <td>Web</td>\n",
       "      <td>Mac Desktop</td>\n",
       "      <td>Firefox</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>87mebub9p4</td>\n",
       "      <td>2010-09-14</td>\n",
       "      <td>20091208061105</td>\n",
       "      <td>2010-02-18</td>\n",
       "      <td>-unknown-</td>\n",
       "      <td>41.0</td>\n",
       "      <td>basic</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>direct</td>\n",
       "      <td>direct</td>\n",
       "      <td>untracked</td>\n",
       "      <td>Web</td>\n",
       "      <td>Mac Desktop</td>\n",
       "      <td>Chrome</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id date_account_created  timestamp_first_active date_first_booking  \\\n",
       "0  gxn3p5htnn           2010-06-28          20090319043255                NaN   \n",
       "1  820tgsjxq7           2011-05-25          20090523174809                NaN   \n",
       "2  4ft3gnwmtx           2010-09-28          20090609231247         2010-08-02   \n",
       "3  bjjt8pjhuk           2011-12-05          20091031060129         2012-09-08   \n",
       "4  87mebub9p4           2010-09-14          20091208061105         2010-02-18   \n",
       "\n",
       "      gender   age signup_method  signup_flow language affiliate_channel  \\\n",
       "0  -unknown-   NaN      facebook            0       en            direct   \n",
       "1       MALE  38.0      facebook            0       en               seo   \n",
       "2     FEMALE  56.0         basic            3       en            direct   \n",
       "3     FEMALE  42.0      facebook            0       en            direct   \n",
       "4  -unknown-  41.0         basic            0       en            direct   \n",
       "\n",
       "  affiliate_provider first_affiliate_tracked signup_app first_device_type  \\\n",
       "0             direct               untracked        Web       Mac Desktop   \n",
       "1             google               untracked        Web       Mac Desktop   \n",
       "2             direct               untracked        Web   Windows Desktop   \n",
       "3             direct               untracked        Web       Mac Desktop   \n",
       "4             direct               untracked        Web       Mac Desktop   \n",
       "\n",
       "  first_browser country_destination  \n",
       "0        Chrome                 NDF  \n",
       "1        Chrome                 NDF  \n",
       "2            IE                  US  \n",
       "3       Firefox               other  \n",
       "4        Chrome                  US  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the data:\n",
    "train_users_2 = pd.read_csv(\"../data/train_users_2.csv\")\n",
    "\n",
    "# Check basic info:\n",
    "print(\"*** Some basic info:\")\n",
    "print(\"'train_users_2' has {} data points with {} variables each.\".format(*train_users_2.shape))\n",
    "print(\"'train_users_2' counts {} missing values.\".format(train_users_2.isnull().sum().sum()))\n",
    "\n",
    "# Give a look to the first lines:\n",
    "print(\"\\n*** First lines:\")\n",
    "display(train_users_2.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## IDs\n",
    "\n",
    "First, we have to make sure that each row of the dataframe concerns unique users, to prevent possible errors, and then, if it's OK, we will drop this feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It's OK: 213451 data points for 213451 unique users.\n"
     ]
    }
   ],
   "source": [
    "# Check unique users in the dataframe:\n",
    "id_unique = len(train_users_2['id'].unique().tolist())\n",
    "if id_unique == train_users_2.shape[0]:\n",
    "    print(\"It's OK: {} data points for {} unique users.\".format(train_users_2.shape[0], id_unique))\n",
    "else:\n",
    "    print(\"It's KO: {} data points for {} unique users.\".format(train_users_2.shape[0], id_unique))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop 'id':\n",
    "dataset = train_users_2.drop('id', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Age\n",
    "\n",
    "Now, we are going to manage the treatment of the `age` feature, handling the outliers, as it has been seen in the previous notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle outliers in the 'age' feature:\n",
    "dataset.loc[dataset['age'] < 16, 'age'] = -1\n",
    "dataset.loc[dataset['age'] > 96, 'age'] = -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Missing values\n",
    "\n",
    "Here, we are going to treat all missing values (`NaN` values) and imprecise values (e.g. `-unknown-`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date_account_created            0\n",
       "timestamp_first_active          0\n",
       "date_first_booking         124543\n",
       "gender                          0\n",
       "age                         87990\n",
       "signup_method                   0\n",
       "signup_flow                     0\n",
       "language                        0\n",
       "affiliate_channel               0\n",
       "affiliate_provider              0\n",
       "first_affiliate_tracked      6065\n",
       "signup_app                      0\n",
       "first_device_type               0\n",
       "first_browser                   0\n",
       "country_destination             0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check missing values by features:\n",
    "display(dataset.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to make some choices:\n",
    "* `date_first_booking` has numerous missing values: We are going to drop this feature\n",
    "* `age` feature has been treated specifically above (outliers), nevertheless, we are going to handle missing values here\n",
    "* `first_affiliate_tracked` will see its missing values replaced by `untracked`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date_account_created       0\n",
       "timestamp_first_active     0\n",
       "gender                     0\n",
       "age                        0\n",
       "signup_method              0\n",
       "signup_flow                0\n",
       "language                   0\n",
       "affiliate_channel          0\n",
       "affiliate_provider         0\n",
       "first_affiliate_tracked    0\n",
       "signup_app                 0\n",
       "first_device_type          0\n",
       "first_browser              0\n",
       "country_destination        0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Drop 'date_first_booking':\n",
    "dataset.drop('date_first_booking', axis=1, inplace=True)\n",
    "\n",
    "# Handle missing values in 'age':\n",
    "dataset['age'].fillna(-1, inplace=True)\n",
    "\n",
    "# Replace in 'first_affiliate_tracked' missing values by 'untracked':\n",
    "dataset['first_affiliate_tracked'].fillna('untracked', inplace=True)\n",
    "\n",
    "# Check for missing values:\n",
    "display(dataset.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Check for imprecise values and transformed missing values:\n",
      "- Column 'gender' possible values:\n",
      "['-unknown-', 'MALE', 'FEMALE', 'OTHER']\n",
      "- Column 'age' possible values:\n",
      "[-1.0, 38.0, 56.0, 42.0, 41.0, 46.0, 47.0, 50.0, 36.0, 37.0, 33.0, 31.0, 29.0, 30.0, 40.0, 26.0, 32.0, 35.0, 59.0, 49.0, 44.0, 34.0, 28.0, 19.0, 53.0, 52.0, 39.0, 57.0, 25.0, 54.0, 69.0, 63.0, 43.0, 55.0, 65.0, 58.0, 61.0, 18.0, 27.0, 45.0, 60.0, 48.0, 51.0, 64.0, 72.0, 70.0, 67.0, 73.0, 66.0, 68.0, 95.0, 24.0, 94.0, 75.0, 79.0, 62.0, 16.0, 23.0, 76.0, 74.0, 87.0, 92.0, 71.0, 84.0, 78.0, 82.0, 77.0, 22.0, 89.0, 21.0, 20.0, 17.0, 86.0, 81.0, 90.0, 88.0, 80.0, 91.0, 83.0, 85.0, 93.0, 96.0]\n",
      "- Column 'signup_method' possible values:\n",
      "['facebook', 'basic', 'google']\n",
      "- Column 'signup_flow' possible values:\n",
      "[0, 3, 2, 1, 24, 8, 6, 5, 10, 25, 12, 4, 16, 15, 20, 21, 23]\n",
      "- Column 'language' possible values:\n",
      "['en', 'fr', 'de', 'es', 'it', 'pt', 'zh', 'ko', 'ja', 'ru', 'pl', 'el', 'sv', 'nl', 'hu', 'da', 'id', 'fi', 'no', 'tr', 'th', 'cs', 'hr', 'ca', 'is']\n",
      "- Column 'affiliate_channel' possible values:\n",
      "['direct', 'seo', 'other', 'sem-non-brand', 'content', 'sem-brand', 'remarketing', 'api']\n",
      "- Column 'affiliate_provider' possible values:\n",
      "['direct', 'google', 'other', 'craigslist', 'facebook', 'vast', 'bing', 'meetup', 'facebook-open-graph', 'email-marketing', 'yahoo', 'padmapper', 'gsp', 'wayn', 'naver', 'baidu', 'yandex', 'daum']\n",
      "- Column 'first_affiliate_tracked' possible values:\n",
      "['untracked', 'omg', 'linked', 'tracked-other', 'product', 'marketing', 'local ops']\n",
      "- Column 'signup_app' possible values:\n",
      "['Web', 'Moweb', 'iOS', 'Android']\n",
      "- Column 'first_device_type' possible values:\n",
      "['Mac Desktop', 'Windows Desktop', 'iPhone', 'Other/Unknown', 'Desktop (Other)', 'Android Tablet', 'iPad', 'Android Phone', 'SmartPhone (Other)']\n",
      "- Column 'first_browser' possible values:\n",
      "['Chrome', 'IE', 'Firefox', 'Safari', '-unknown-', 'Mobile Safari', 'Chrome Mobile', 'RockMelt', 'Chromium', 'Android Browser', 'AOL Explorer', 'Palm Pre web browser', 'Mobile Firefox', 'Opera', 'TenFourFox', 'IE Mobile', 'Apple Mail', 'Silk', 'Camino', 'Arora', 'BlackBerry Browser', 'SeaMonkey', 'Iron', 'Sogou Explorer', 'IceWeasel', 'Opera Mini', 'SiteKiosk', 'Maxthon', 'Kindle Browser', 'CoolNovo', 'Conkeror', 'wOSBrowser', 'Google Earth', 'Crazy Browser', 'Mozilla', 'OmniWeb', 'PS Vita browser', 'NetNewsWire', 'CometBird', 'Comodo Dragon', 'Flock', 'Pale Moon', 'Avant Browser', 'Opera Mobile', 'Yandex.Browser', 'TheWorld Browser', 'SlimBrowser', 'Epic', 'Stainless', 'Googlebot', 'Outlook 2007', 'IceDragon']\n"
     ]
    }
   ],
   "source": [
    "# Check for imprecise values and transformed missing values:\n",
    "dataset_cols = []\n",
    "for col in dataset.columns:\n",
    "    dataset_cols.append(col)\n",
    "dataset_cols.remove('date_account_created')\n",
    "dataset_cols.remove('timestamp_first_active')\n",
    "dataset_cols.remove('country_destination')\n",
    "print(\"*** Check for imprecise values and transformed missing values:\")\n",
    "for col in dataset_cols:\n",
    "    print(\"- Column '{}' possible values:\\n{}\".format(col, dataset[col].unique().tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to \"penalize\" imprecise values and transformed missing values, we are going to evaluate below the number of unknown things for a given user, and add it to the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Penalize imprecise values and transformed missing values:\n",
    "dataset['nans'] = np.sum([(dataset['gender']=='-unknown-'),\n",
    "                          (dataset['age']==-1),\n",
    "                          (dataset['first_affiliate_tracked']=='untracked'),\n",
    "                          (dataset['first_browser']=='-unknown-')\n",
    "                         ], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Dates\n",
    "\n",
    "Here, we are going to transform the 2 remaining dates, `date_account_created` and `timestamp_first_active`, and extract from them the valuable information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cast dates to proper format:\n",
    "dataset['date_account_created'] = pd.to_datetime(dataset['date_account_created'])\n",
    "dataset['date_first_active'] = pd.to_datetime(dataset['timestamp_first_active'], format='%Y%m%d%H%M%S')\n",
    "\n",
    "# Convert dates to 'DateTime Index':\n",
    "date_account_created = pd.DatetimeIndex(dataset['date_account_created'])\n",
    "date_first_active = pd.DatetimeIndex(dataset['date_first_active'])\n",
    "\n",
    "# Split dates into day, week, month and year:\n",
    "dataset['day_account_created'] = date_account_created.day\n",
    "dataset['weekday_account_created'] = date_account_created.weekday\n",
    "dataset['week_account_created'] = date_account_created.week\n",
    "dataset['month_account_created'] = date_account_created.month\n",
    "dataset['year_account_created'] = date_account_created.year\n",
    "dataset['day_first_active'] = date_first_active.day\n",
    "dataset['weekday_first_active'] = date_first_active.weekday\n",
    "dataset['week_first_active'] = date_first_active.week\n",
    "dataset['month_first_active'] = date_first_active.month\n",
    "dataset['year_first_active'] = date_first_active.year\n",
    "\n",
    "# Calculate time lag between first activity date and account creation date:\n",
    "dataset['time_lag'] = (date_account_created.values - date_first_active.values).astype(int)\n",
    "\n",
    "# Drop the now useless variables from the data set:\n",
    "fields_to_drop = ['date_account_created',\n",
    "                  'date_first_active',\n",
    "                  'timestamp_first_active']\n",
    "dataset.drop(fields_to_drop, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Categorical features\n",
    "\n",
    "It's now time to handle the categorical variables of our dataset, to include them in our model, and for that, we will need to make binary dummy variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of fields to dummify:\n",
    "dummy_fields = ['gender',\n",
    "                'signup_method',\n",
    "                'signup_flow',\n",
    "                'language',\n",
    "                'affiliate_channel',\n",
    "                'affiliate_provider',\n",
    "                'first_affiliate_tracked',\n",
    "                'signup_app',\n",
    "                'first_device_type',\n",
    "                'first_browser']\n",
    "\n",
    "# Create dummy variables and add them to the data set:\n",
    "for each in dummy_fields:\n",
    "    dummies = pd.get_dummies(dataset[each], prefix=each, drop_first=False)\n",
    "    dataset = pd.concat([dataset, dummies], axis=1)\n",
    "\n",
    "# Drop now useless variables from the data set:\n",
    "dataset.drop(dummy_fields, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Continuous variables\n",
    "\n",
    "Finally, we are going to standardize each of the continuous variables, that is, we will shift and scale the variables such that they have 0 mean and a standard deviation of 1.\n",
    "\n",
    "*Nota Bene:* Due to the fact that we have introduced the value `-1` for `NaN` values and outliers for the `age` feature, we are not going to treat it here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the continuous variables to standardize:\n",
    "continuous_features = ['nans', 'time_lag']\n",
    "\n",
    "# Store scalings in a dictionary to convert back later and standardize:\n",
    "scaled_features = {}\n",
    "for each in continuous_features:\n",
    "    mean, std = dataset[each].mean(), dataset[each].std()\n",
    "    scaled_features[each] = [mean, std]\n",
    "    dataset.loc[:, each] = (dataset[each] - mean)/std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Save our work\n",
    "\n",
    "Our dataset is now consolidated: Before going further, we can save it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.to_csv(\"../data/consolidated_dataset.csv\", header=True, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
