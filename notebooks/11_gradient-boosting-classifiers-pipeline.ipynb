{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting Classifiers Pipeline\n",
    "---\n",
    "\n",
    "## Introduction\n",
    "\n",
    "For the moment, we have not built models which reaches significantly better results than the ones obtained by the naive prediction model we use for benchmarking.\n",
    "\n",
    "Furthermore, the results we obtained for first booking destination countries whose presence in the dataset is significantly low (all the ones except `NDF`, `USA` and `other`) are very bad.\n",
    "\n",
    "To try to handle successfully this situation, we are going to build a **gradient boosting classifiers pipeline**, and decompose its action into 4 steps before providing predictions when a given sample data is proposed:\n",
    "* A first step where a first gradient boosting classifier will have the task to determine exclusively if the fisrt booking destination country is `NDF`.\n",
    "* If the prevision provided by this first gradient boosting classifier is different from `NDF`, then, a second step will be performed, where a second gradient boosting classifier will have the task to determine exclusively if the first booking destination country is `USA`.\n",
    "* If the prevision provided by this second gradient boosting classifier is different from `USA`, then, a third step will be performed, where a third gradient boosting classifier will have the task to determine exclusively if the first booking destination country is `other`.\n",
    "* Lastly, if the prevision provided by this third gradient boosting classifier is different from `other`, then, a fourth step will be performed, where a fourth gradient boosting classifier will have the task to determine the first booking destination country among the remaining possibilities for a first booking destination country (`FR`, `IT`, `GB`, `ES`, `CA`, `DE`, `NL`, `AU` and `PT`).\n",
    "\n",
    "*Nota Bene:* We choose to exploit gradient boosting classifiers because they are the ones which have appeared to handle the best the data used in the current project.\n",
    "\n",
    "As always, the prerequisite step consists on loading the appropriate packages to perform our work:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activate 'airbnb' environment:\n",
    "!source activate airbnb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/envs/airbnb/lib/python3.7/site-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# Needed packages:\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.externals import joblib\n",
    "from utils import (create_training_testing_datasets,\n",
    "                   calculate_dcg,\n",
    "                   calculate_ndcg,\n",
    "                   clf_prediction,\n",
    "                   ndcg_mean_score_calc,\n",
    "                   detailed_ndcg_mean_score_calc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Construct a gradient boosting classifiers pipeline\n",
    "\n",
    "### Create global training and testing datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Some basic info:\n",
      "'consolidated_dataset' has 213451 data points with 161 variables each.\n",
      "'consolidated_dataset' counts 0 missing values.\n",
      "\n",
      "*** First lines:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>country_destination</th>\n",
       "      <th>nans</th>\n",
       "      <th>day_account_created</th>\n",
       "      <th>weekday_account_created</th>\n",
       "      <th>week_account_created</th>\n",
       "      <th>month_account_created</th>\n",
       "      <th>year_account_created</th>\n",
       "      <th>day_first_active</th>\n",
       "      <th>weekday_first_active</th>\n",
       "      <th>...</th>\n",
       "      <th>first_browser_SeaMonkey</th>\n",
       "      <th>first_browser_Silk</th>\n",
       "      <th>first_browser_SiteKiosk</th>\n",
       "      <th>first_browser_SlimBrowser</th>\n",
       "      <th>first_browser_Sogou Explorer</th>\n",
       "      <th>first_browser_Stainless</th>\n",
       "      <th>first_browser_TenFourFox</th>\n",
       "      <th>first_browser_TheWorld Browser</th>\n",
       "      <th>first_browser_Yandex.Browser</th>\n",
       "      <th>first_browser_wOSBrowser</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>NDF</td>\n",
       "      <td>1.225078</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>6</td>\n",
       "      <td>2010</td>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38.0</td>\n",
       "      <td>NDF</td>\n",
       "      <td>-0.453135</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>5</td>\n",
       "      <td>2011</td>\n",
       "      <td>23</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>56.0</td>\n",
       "      <td>US</td>\n",
       "      <td>-0.453135</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>9</td>\n",
       "      <td>2010</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>42.0</td>\n",
       "      <td>other</td>\n",
       "      <td>-0.453135</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>12</td>\n",
       "      <td>2011</td>\n",
       "      <td>31</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41.0</td>\n",
       "      <td>US</td>\n",
       "      <td>0.385972</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>9</td>\n",
       "      <td>2010</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 161 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    age country_destination      nans  day_account_created  \\\n",
       "0  -1.0                 NDF  1.225078                   28   \n",
       "1  38.0                 NDF -0.453135                   25   \n",
       "2  56.0                  US -0.453135                   28   \n",
       "3  42.0               other -0.453135                    5   \n",
       "4  41.0                  US  0.385972                   14   \n",
       "\n",
       "   weekday_account_created  week_account_created  month_account_created  \\\n",
       "0                        0                    26                      6   \n",
       "1                        2                    21                      5   \n",
       "2                        1                    39                      9   \n",
       "3                        0                    49                     12   \n",
       "4                        1                    37                      9   \n",
       "\n",
       "   year_account_created  day_first_active  weekday_first_active  ...  \\\n",
       "0                  2010                19                     3  ...   \n",
       "1                  2011                23                     5  ...   \n",
       "2                  2010                 9                     1  ...   \n",
       "3                  2011                31                     5  ...   \n",
       "4                  2010                 8                     1  ...   \n",
       "\n",
       "   first_browser_SeaMonkey  first_browser_Silk  first_browser_SiteKiosk  \\\n",
       "0                        0                   0                        0   \n",
       "1                        0                   0                        0   \n",
       "2                        0                   0                        0   \n",
       "3                        0                   0                        0   \n",
       "4                        0                   0                        0   \n",
       "\n",
       "   first_browser_SlimBrowser  first_browser_Sogou Explorer  \\\n",
       "0                          0                             0   \n",
       "1                          0                             0   \n",
       "2                          0                             0   \n",
       "3                          0                             0   \n",
       "4                          0                             0   \n",
       "\n",
       "   first_browser_Stainless  first_browser_TenFourFox  \\\n",
       "0                        0                         0   \n",
       "1                        0                         0   \n",
       "2                        0                         0   \n",
       "3                        0                         0   \n",
       "4                        0                         0   \n",
       "\n",
       "   first_browser_TheWorld Browser  first_browser_Yandex.Browser  \\\n",
       "0                               0                             0   \n",
       "1                               0                             0   \n",
       "2                               0                             0   \n",
       "3                               0                             0   \n",
       "4                               0                             0   \n",
       "\n",
       "   first_browser_wOSBrowser  \n",
       "0                         0  \n",
       "1                         0  \n",
       "2                         0  \n",
       "3                         0  \n",
       "4                         0  \n",
       "\n",
       "[5 rows x 161 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the data:\n",
    "consolidated_dataset = pd.read_csv(\"../data/consolidated_dataset.csv\")\n",
    "\n",
    "# Check basic info:\n",
    "print(\"*** Some basic info:\")\n",
    "print(\"'consolidated_dataset' has {} data points with {} variables each.\".format(*consolidated_dataset.shape))\n",
    "print(\"'consolidated_dataset' counts {} missing values.\".format(consolidated_dataset.isnull().sum().sum()))\n",
    "\n",
    "# Give a look to the first lines:\n",
    "print(\"\\n*** First lines:\")\n",
    "display(consolidated_dataset.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training and testing datasets:\n",
    "X_train, X_test, y_train, y_test, encoding_dict = create_training_testing_datasets(consolidated_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a training dataset for each gradient boosting classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Encoding dictionary:\n",
      "- Country AU: Code 0\n",
      "- Country CA: Code 1\n",
      "- Country DE: Code 2\n",
      "- Country ES: Code 3\n",
      "- Country FR: Code 4\n",
      "- Country GB: Code 5\n",
      "- Country IT: Code 6\n",
      "- Country NDF: Code 7\n",
      "- Country NL: Code 8\n",
      "- Country PT: Code 9\n",
      "- Country US: Code 10\n",
      "- Country other: Code 11\n"
     ]
    }
   ],
   "source": [
    "# Parameters of the global encoding dictionary:\n",
    "print(\"*** Encoding dictionary:\")\n",
    "for country, country_code in encoding_dict.items():\n",
    "    print(\"- Country {}: Code {}\".format(country, country_code))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training dataset for first gradient boosting classifier:\n",
    "X_train_1 = np.copy(X_train)\n",
    "y_train_1 = np.copy(y_train)\n",
    "y_train_1 = np.where(y_train_1==7, 0, 1)\n",
    "\n",
    "# Training dataset for second gradient boosting classifier:\n",
    "X_train_2 = np.copy(X_train)\n",
    "y_train_2 = np.copy(y_train)\n",
    "idc_to_rm = np.argwhere(y_train_2==7)\n",
    "X_train_2 = np.delete(X_train_2, idc_to_rm, axis=0)\n",
    "y_train_2 = np.delete(y_train_2, idc_to_rm)\n",
    "y_train_2 = np.where(y_train_2==10, 0, 1)\n",
    "\n",
    "# Training dataset for third gradient boosting classifier:\n",
    "X_train_3 = np.copy(X_train)\n",
    "y_train_3 = np.copy(y_train)\n",
    "idc_to_rm = np.argwhere(y_train_3==7)\n",
    "X_train_3 = np.delete(X_train_3, idc_to_rm, axis=0)\n",
    "y_train_3 = np.delete(y_train_3, idc_to_rm)\n",
    "idc_to_rm = np.argwhere(y_train_3==10)\n",
    "X_train_3 = np.delete(X_train_3, idc_to_rm, axis=0)\n",
    "y_train_3 = np.delete(y_train_3, idc_to_rm)\n",
    "y_train_3 = np.where(y_train_3==11, 0, 1)\n",
    "\n",
    "# Training dataset for fourth gradient boosting classifier:\n",
    "X_train_4 = np.copy(X_train)\n",
    "y_train_4 = np.copy(y_train)\n",
    "idc_to_rm = np.argwhere(y_train_4==7)\n",
    "X_train_4 = np.delete(X_train_4, idc_to_rm, axis=0)\n",
    "y_train_4 = np.delete(y_train_4, idc_to_rm)\n",
    "idc_to_rm = np.argwhere(y_train_4==10)\n",
    "X_train_4 = np.delete(X_train_4, idc_to_rm, axis=0)\n",
    "y_train_4 = np.delete(y_train_4, idc_to_rm)\n",
    "idc_to_rm = np.argwhere(y_train_4==11)\n",
    "X_train_4 = np.delete(X_train_4, idc_to_rm, axis=0)\n",
    "y_train_4 = np.delete(y_train_4, idc_to_rm)\n",
    "y_train_4 = np.where(y_train_4==8, 7, y_train_4)\n",
    "y_train_4 = np.where(y_train_4==9, 8, y_train_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train first gradient boosting classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time info about classifier training:\n",
      "CPU times: user 2min 58s, sys: 1.54 s, total: 2min 59s\n",
      "Wall time: 2min 41s\n"
     ]
    }
   ],
   "source": [
    "# Initialize gradient boosting classifier:\n",
    "gb_clf = GradientBoostingClassifier(random_state=42)\n",
    "\n",
    "# Train the classifier:\n",
    "print(\"Time info about classifier training:\")\n",
    "%time gb_clf_1 = gb_clf.fit(X_train_1, y_train_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean accuracy on training dataset of 'gb_clf_1' is: 0.697980\n"
     ]
    }
   ],
   "source": [
    "# Check mean accuracy on training dataset:\n",
    "mean_accuracy = gb_clf_1.score(X_train_1, y_train_1)\n",
    "print(\"The mean accuracy on training dataset of 'gb_clf_1' is: {:.6f}\".format(mean_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../models/gb_clf_1.pkl']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save model:\n",
    "joblib.dump(gb_clf_1, \"../models/gb_clf_1.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train second gradient boosting classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time info about classifier training:\n",
      "CPU times: user 51.5 s, sys: 289 ms, total: 51.7 s\n",
      "Wall time: 51.5 s\n"
     ]
    }
   ],
   "source": [
    "# Initialize gradient boosting classifier:\n",
    "gb_clf = GradientBoostingClassifier(random_state=42)\n",
    "\n",
    "# Train the classifier:\n",
    "print(\"Time info about classifier training:\")\n",
    "%time gb_clf_2 = gb_clf.fit(X_train_2, y_train_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean accuracy on training dataset of 'gb_clf_2' is: 0.703231\n"
     ]
    }
   ],
   "source": [
    "# Check mean accuracy on training dataset:\n",
    "mean_accuracy = gb_clf_2.score(X_train_2, y_train_2)\n",
    "print(\"The mean accuracy on training dataset of 'gb_clf_2' is: {:.6f}\".format(mean_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../models/gb_clf_2.pkl']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save model:\n",
    "joblib.dump(gb_clf_2, \"../models/gb_clf_2.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train third gradient boosting classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time info about classifier training:\n",
      "CPU times: user 12.5 s, sys: 66.3 ms, total: 12.5 s\n",
      "Wall time: 12.5 s\n"
     ]
    }
   ],
   "source": [
    "# Initialize gradient boosting classifier:\n",
    "gb_clf = GradientBoostingClassifier(random_state=42)\n",
    "\n",
    "# Train the classifier:\n",
    "print(\"Time info about classifier training:\")\n",
    "%time gb_clf_3 = gb_clf.fit(X_train_3, y_train_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean accuracy on training dataset of 'gb_clf_3' is: 0.643015\n"
     ]
    }
   ],
   "source": [
    "# Check mean accuracy on training dataset:\n",
    "mean_accuracy = gb_clf_3.score(X_train_3, y_train_3)\n",
    "print(\"The mean accuracy on training dataset of 'gb_clf_3' is: {:.6f}\".format(mean_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../models/gb_clf_3.pkl']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save model:\n",
    "joblib.dump(gb_clf_3, \"../models/gb_clf_3.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train fourth gradient boosting classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time info about classifier training:\n",
      "CPU times: user 2min 3s, sys: 2.67 s, total: 2min 5s\n",
      "Wall time: 1min 3s\n"
     ]
    }
   ],
   "source": [
    "# Initialize gradient boosting classifier:\n",
    "gb_clf = GradientBoostingClassifier(random_state=42)\n",
    "\n",
    "# Train the classifier:\n",
    "print(\"Time info about classifier training:\")\n",
    "%time gb_clf_4 = gb_clf.fit(X_train_4, y_train_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean accuracy on training dataset of 'gb_clf_3' is: 0.352471\n"
     ]
    }
   ],
   "source": [
    "# Check mean accuracy on training dataset:\n",
    "mean_accuracy = gb_clf_4.score(X_train_4, y_train_4)\n",
    "print(\"The mean accuracy on training dataset of 'gb_clf_3' is: {:.6f}\".format(mean_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../models/gb_clf_4.pkl']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save model:\n",
    "joblib.dump(gb_clf_4, \"../models/gb_clf_4.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient boosting classifiers pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build prediction mechanism of gradient boosting classifiers pipeline:\n",
    "\n",
    "def gb_clfs_pipeline_prediction(clf_1, clf_2, clf_3, clf_4, sample_data):\n",
    "    \"\"\" Perform predictions thanks to gradient boosting classifiers pipeline \"\"\"\n",
    "    \n",
    "    # Perform predictions with first classifier:\n",
    "    pred_probs_1 = clf_1.predict_proba(sample_data.reshape(1, -1)).tolist()[0]\n",
    "    pred_probs_1_list = [x[1] for x in sorted(zip(pred_probs_1, range(2)), reverse=True)]\n",
    "    \n",
    "    # Test results from first classifier:\n",
    "    if pred_probs_1_list[0] == 0:\n",
    "        preds_list = [7, 10, 11, 4, 6]\n",
    "    else:\n",
    "        \n",
    "        # Perform predictions with second classifier:\n",
    "        pred_probs_2 = clf_2.predict_proba(sample_data.reshape(1, -1)).tolist()[0]\n",
    "        pred_probs_2_list = [x[1] for x in sorted(zip(pred_probs_2, range(2)), reverse=True)]\n",
    "        \n",
    "        # Test results from second classifier:\n",
    "        if pred_probs_2_list[0] == 0:\n",
    "            preds_list = [10, 7, 11, 4, 6]\n",
    "        else:\n",
    "            \n",
    "            # Perform predictions with third classifier:\n",
    "            pred_probs_3 = clf_3.predict_proba(sample_data.reshape(1, -1)).tolist()[0]\n",
    "            pred_probs_3_list = [x[1] for x in sorted(zip(pred_probs_3, range(2)), reverse=True)]\n",
    "            \n",
    "            # Test results from third classifier:\n",
    "            if pred_probs_3_list[0] == 0:\n",
    "                preds_list = [11, 7, 10, 4, 6]\n",
    "            else:\n",
    "                \n",
    "                # Perform predictions with fourth classifier:\n",
    "                pred_probs_4 = clf_4.predict_proba(sample_data.reshape(1, -1)).tolist()[0]\n",
    "                pred_probs_4_list = [x[1] for x in sorted(zip(pred_probs_4, range(9)), reverse=True) if x[0] != 0.]\n",
    "                preds_list = pred_probs_4_list + [7, 10, 11]\n",
    "    \n",
    "    # Return result:\n",
    "    return preds_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time info about classifier prediction:\n",
      "CPU times: user 1.85 ms, sys: 162 µs, total: 2.01 ms\n",
      "Wall time: 986 µs\n",
      "***\n",
      "For the classifier check:\n",
      "- Real first booking destination country: US\n",
      "- Predictions list: ['US', 'NDF', 'other', 'FR', 'IT']\n"
     ]
    }
   ],
   "source": [
    "# Perform one prediction to check classifier:\n",
    "print(\"Time info about classifier prediction:\")\n",
    "%time preds_list = gb_clfs_pipeline_prediction(gb_clf_1, gb_clf_2, gb_clf_3, gb_clf_4, X_train[0])\n",
    "print(\"***\")\n",
    "\n",
    "# Reverse encoding dictionary:\n",
    "decoding_dict = dict(map(reversed, encoding_dict.items()))\n",
    "\n",
    "# Print result:\n",
    "print(\"For the classifier check:\")\n",
    "print(\"- Real first booking destination country: {}\".format(decoding_dict[y_train[0]]))\n",
    "print(\"- Predictions list: {}\".format([decoding_dict[x] for x in preds_list]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Check performances of the gradient boosting classifiers pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapt nDCG mean score calculators:\n",
    "\n",
    "def ndcg_mean_score_calc_3(clf_1, clf_2, clf_3, clf_4, X, y):\n",
    "    \"\"\" Calculate nDCG mean score on a labeled dataset \"\"\"\n",
    "    \n",
    "    # Set nDCG scores list:\n",
    "    ndcg_scores_list = []\n",
    "    \n",
    "    # Loop on labeled dataset:\n",
    "    for i in range(len(y)):\n",
    "        ndcg_score = calculate_ndcg(gb_clfs_pipeline_prediction(clf_1, clf_2, clf_3, clf_4, X[i]), y[i])\n",
    "        ndcg_scores_list.append(ndcg_score)\n",
    "        \n",
    "    # Determine nDCG mean score:\n",
    "    ndcg_mean_score = np.mean(ndcg_scores_list)\n",
    "    \n",
    "    # Return result:\n",
    "    return ndcg_mean_score\n",
    "\n",
    "def detailed_ndcg_mean_score_calc_3(clf_1, clf_2, clf_3, clf_4, X, y, encoding_dict):\n",
    "    \"\"\" Calculate nDCG mean score on a labeled dataset for each class \"\"\"\n",
    "    \n",
    "    # Reverse encoding dictionary:\n",
    "    decoding_dict = dict(map(reversed, encoding_dict.items()))\n",
    "    \n",
    "    # Set nDCG scores objects:\n",
    "    ndcg_scores_dict = {country_dest: [] for country_dest in range(12)}\n",
    "    ndcg_mean_scores_list = []\n",
    "    \n",
    "    # Loop on labeled dataset:\n",
    "    for i in range(len(y)):\n",
    "        ndcg_score = calculate_ndcg(gb_clfs_pipeline_prediction(clf_1, clf_2, clf_3, clf_4, X[i]), y[i])\n",
    "        ndcg_scores_dict[y[i]].append(ndcg_score)\n",
    "        \n",
    "    # Loop on country destinations:\n",
    "    for country_dest in range(12):\n",
    "        ndcg_mean_scores_list.append(np.mean(ndcg_scores_dict[country_dest]))\n",
    "        \n",
    "    # Return result:\n",
    "    return ndcg_mean_scores_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time info about nDCG mean score calculation on training dataset:\n",
      "CPU times: user 60 s, sys: 483 ms, total: 1min\n",
      "Wall time: 1min\n",
      "***\n",
      "On training dataset, classifier nDCG mean score is 0.823940.\n"
     ]
    }
   ],
   "source": [
    "# Calculate nDCG mean score on training dataset:\n",
    "print(\"Time info about nDCG mean score calculation on training dataset:\")\n",
    "%time ndcg_mean_score = ndcg_mean_score_calc_3(gb_clf_1, gb_clf_2, gb_clf_3, gb_clf_4, X_train, y_train)\n",
    "print(\"***\")\n",
    "print(\"On training dataset, classifier nDCG mean score is {:.6f}.\".format(ndcg_mean_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time info about nDCG mean score calculation on testing dataset:\n",
      "CPU times: user 14.9 s, sys: 111 ms, total: 15 s\n",
      "Wall time: 15 s\n",
      "***\n",
      "On testing dataset, classifier nDCG mean score is 0.822982.\n"
     ]
    }
   ],
   "source": [
    "# Calculate nDCG mean score on testing dataset:\n",
    "print(\"Time info about nDCG mean score calculation on testing dataset:\")\n",
    "%time ndcg_mean_score = ndcg_mean_score_calc_3(gb_clf_1, gb_clf_2, gb_clf_3, gb_clf_4, X_test, y_test)\n",
    "print(\"***\")\n",
    "print(\"On testing dataset, classifier nDCG mean score is {:.6f}.\".format(ndcg_mean_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time info about nDCG mean score calculation for each class on testing dataset:\n",
      "CPU times: user 15 s, sys: 122 ms, total: 15.1 s\n",
      "Wall time: 15 s\n",
      "***\n",
      "Detailed results for each class on testing dataset:\n",
      "nDCG mean score for AU: 0.000000\n",
      "nDCG mean score for CA: 0.000000\n",
      "nDCG mean score for DE: 0.002976\n",
      "nDCG mean score for ES: 0.004444\n",
      "nDCG mean score for FR: 0.433142\n",
      "nDCG mean score for GB: 0.002001\n",
      "nDCG mean score for IT: 0.388995\n",
      "nDCG mean score for NDF: 0.926442\n",
      "nDCG mean score for NL: 0.000000\n",
      "nDCG mean score for PT: 0.000000\n",
      "nDCG mean score for US: 0.832884\n",
      "nDCG mean score for other: 0.499009\n"
     ]
    }
   ],
   "source": [
    "# Calculate nDCG mean score for each class on testing dataset:\n",
    "print(\"Time info about nDCG mean score calculation for each class on testing dataset:\")\n",
    "%time ndcg_mean_scores_list = detailed_ndcg_mean_score_calc_3(gb_clf_1, gb_clf_2, gb_clf_3, gb_clf_4, X_test, y_test, encoding_dict)\n",
    "print(\"***\")\n",
    "print(\"Detailed results for each class on testing dataset:\")\n",
    "for country_dest in range(12):\n",
    "    print(\"nDCG mean score for {}: {:.6f}\".format(decoding_dict[country_dest],\n",
    "                                                  ndcg_mean_scores_list[country_dest]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "As a quick conclusion, for the results obtained for this gradient boosting classifiers pipeline, we can note 4 major elements in comparison with the gradient boosting classifier we have built previously (the one which reached the best results):\n",
    "* On testing dataset, it gets a worse nDCG mean score than the one obtained by the gradient boosting classifier.\n",
    "* On testing dataset, it gets better nDCG mean scores for predicting correctly France, Italy, USA and other than the ones obtained by the gradient boosting classifier.\n",
    "* On testing dataset, it gets worse nDCG mean scores for predicting correctly Australia, Canada, Germany, Spain, Great Britain, no destination found and Netherlands USA than the ones obtained by the gradient boosting classifier.\n",
    "* On testing dataset, it is as \"bad\" as the gradient boosting classifier for predicting correctly Portugal."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
