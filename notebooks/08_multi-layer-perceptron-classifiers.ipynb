{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Layer Perceptron Classifiers\n",
    "---\n",
    "\n",
    "## Introduction\n",
    "\n",
    "The fifth models we are going to use to try tackling the current problem are **multi-layer perceptron classifiers**.\n",
    "\n",
    "As always, the prerequisite step consists on loading the appropriate packages to perform our work:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activate 'airbnb' environment:\n",
    "!source activate airbnb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/envs/airbnb/lib/python3.7/site-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# Needed packages:\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.externals import joblib\n",
    "from utils import (create_training_testing_datasets,\n",
    "                   calculate_dcg,\n",
    "                   calculate_ndcg,\n",
    "                   clf_prediction,\n",
    "                   ndcg_mean_score_calc,\n",
    "                   detailed_ndcg_mean_score_calc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Create training and testing datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Some basic info:\n",
      "'consolidated_dataset' has 213451 data points with 161 variables each.\n",
      "'consolidated_dataset' counts 0 missing values.\n",
      "\n",
      "*** First lines:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>country_destination</th>\n",
       "      <th>nans</th>\n",
       "      <th>day_account_created</th>\n",
       "      <th>weekday_account_created</th>\n",
       "      <th>week_account_created</th>\n",
       "      <th>month_account_created</th>\n",
       "      <th>year_account_created</th>\n",
       "      <th>day_first_active</th>\n",
       "      <th>weekday_first_active</th>\n",
       "      <th>...</th>\n",
       "      <th>first_browser_SeaMonkey</th>\n",
       "      <th>first_browser_Silk</th>\n",
       "      <th>first_browser_SiteKiosk</th>\n",
       "      <th>first_browser_SlimBrowser</th>\n",
       "      <th>first_browser_Sogou Explorer</th>\n",
       "      <th>first_browser_Stainless</th>\n",
       "      <th>first_browser_TenFourFox</th>\n",
       "      <th>first_browser_TheWorld Browser</th>\n",
       "      <th>first_browser_Yandex.Browser</th>\n",
       "      <th>first_browser_wOSBrowser</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>NDF</td>\n",
       "      <td>1.225078</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>6</td>\n",
       "      <td>2010</td>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38.0</td>\n",
       "      <td>NDF</td>\n",
       "      <td>-0.453135</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>5</td>\n",
       "      <td>2011</td>\n",
       "      <td>23</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>56.0</td>\n",
       "      <td>US</td>\n",
       "      <td>-0.453135</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>9</td>\n",
       "      <td>2010</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>42.0</td>\n",
       "      <td>other</td>\n",
       "      <td>-0.453135</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>12</td>\n",
       "      <td>2011</td>\n",
       "      <td>31</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41.0</td>\n",
       "      <td>US</td>\n",
       "      <td>0.385972</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>9</td>\n",
       "      <td>2010</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 161 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    age country_destination      nans  day_account_created  \\\n",
       "0  -1.0                 NDF  1.225078                   28   \n",
       "1  38.0                 NDF -0.453135                   25   \n",
       "2  56.0                  US -0.453135                   28   \n",
       "3  42.0               other -0.453135                    5   \n",
       "4  41.0                  US  0.385972                   14   \n",
       "\n",
       "   weekday_account_created  week_account_created  month_account_created  \\\n",
       "0                        0                    26                      6   \n",
       "1                        2                    21                      5   \n",
       "2                        1                    39                      9   \n",
       "3                        0                    49                     12   \n",
       "4                        1                    37                      9   \n",
       "\n",
       "   year_account_created  day_first_active  weekday_first_active  ...  \\\n",
       "0                  2010                19                     3  ...   \n",
       "1                  2011                23                     5  ...   \n",
       "2                  2010                 9                     1  ...   \n",
       "3                  2011                31                     5  ...   \n",
       "4                  2010                 8                     1  ...   \n",
       "\n",
       "   first_browser_SeaMonkey  first_browser_Silk  first_browser_SiteKiosk  \\\n",
       "0                        0                   0                        0   \n",
       "1                        0                   0                        0   \n",
       "2                        0                   0                        0   \n",
       "3                        0                   0                        0   \n",
       "4                        0                   0                        0   \n",
       "\n",
       "   first_browser_SlimBrowser  first_browser_Sogou Explorer  \\\n",
       "0                          0                             0   \n",
       "1                          0                             0   \n",
       "2                          0                             0   \n",
       "3                          0                             0   \n",
       "4                          0                             0   \n",
       "\n",
       "   first_browser_Stainless  first_browser_TenFourFox  \\\n",
       "0                        0                         0   \n",
       "1                        0                         0   \n",
       "2                        0                         0   \n",
       "3                        0                         0   \n",
       "4                        0                         0   \n",
       "\n",
       "   first_browser_TheWorld Browser  first_browser_Yandex.Browser  \\\n",
       "0                               0                             0   \n",
       "1                               0                             0   \n",
       "2                               0                             0   \n",
       "3                               0                             0   \n",
       "4                               0                             0   \n",
       "\n",
       "   first_browser_wOSBrowser  \n",
       "0                         0  \n",
       "1                         0  \n",
       "2                         0  \n",
       "3                         0  \n",
       "4                         0  \n",
       "\n",
       "[5 rows x 161 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the data:\n",
    "consolidated_dataset = pd.read_csv(\"../data/consolidated_dataset.csv\")\n",
    "\n",
    "# Check basic info:\n",
    "print(\"*** Some basic info:\")\n",
    "print(\"'consolidated_dataset' has {} data points with {} variables each.\".format(*consolidated_dataset.shape))\n",
    "print(\"'consolidated_dataset' counts {} missing values.\".format(consolidated_dataset.isnull().sum().sum()))\n",
    "\n",
    "# Give a look to the first lines:\n",
    "print(\"\\n*** First lines:\")\n",
    "display(consolidated_dataset.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training and testing datasets:\n",
    "X_train, X_test, y_train, y_test, encoding_dict = create_training_testing_datasets(consolidated_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Calculate Normalized DCG scores\n",
    "\n",
    "### \"Out-of-the-box\" multi-layer perceptron classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time info about classifier training:\n",
      "CPU times: user 20min 38s, sys: 25.2 s, total: 21min 4s\n",
      "Wall time: 10min 38s\n"
     ]
    }
   ],
   "source": [
    "# Initialize the classifier:\n",
    "mlp_clf = MLPClassifier(random_state=42)\n",
    "\n",
    "# Train the classifier:\n",
    "print(\"Time info about classifier training:\")\n",
    "%time ootb_mlp_clf = mlp_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time info about classifier prediction:\n",
      "CPU times: user 71.6 ms, sys: 6.81 ms, total: 78.4 ms\n",
      "Wall time: 179 ms\n",
      "***\n",
      "For the classifier check:\n",
      "- Real first booking destination country: US\n",
      "- Predictions list: ['US', 'NDF', 'other', 'FR', 'IT', 'ES', 'GB', 'CA', 'NL', 'DE', 'AU', 'PT']\n"
     ]
    }
   ],
   "source": [
    "# Perform one prediction to check classifier:\n",
    "print(\"Time info about classifier prediction:\")\n",
    "%time preds_list = clf_prediction(ootb_mlp_clf, X_train[0])\n",
    "print(\"***\")\n",
    "\n",
    "# Reverse encoding dictionary:\n",
    "decoding_dict = dict(map(reversed, encoding_dict.items()))\n",
    "\n",
    "# Print result:\n",
    "print(\"For the classifier check:\")\n",
    "print(\"- Real first booking destination country: {}\".format(decoding_dict[y_train[0]]))\n",
    "print(\"- Predictions list: {}\".format([decoding_dict[x] for x in preds_list]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time info about nDCG mean score calculation on training dataset:\n",
      "CPU times: user 1min 23s, sys: 1.25 s, total: 1min 24s\n",
      "Wall time: 42.2 s\n",
      "***\n",
      "On training dataset, classifier nDCG mean score is 0.825010.\n"
     ]
    }
   ],
   "source": [
    "# Calculate nDCG mean score on training dataset:\n",
    "print(\"Time info about nDCG mean score calculation on training dataset:\")\n",
    "%time ndcg_mean_score = ndcg_mean_score_calc(ootb_mlp_clf, X_train, y_train)\n",
    "print(\"***\")\n",
    "print(\"On training dataset, classifier nDCG mean score is {:.6f}.\".format(ndcg_mean_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time info about nDCG mean score calculation on testing dataset:\n",
      "CPU times: user 21 s, sys: 332 ms, total: 21.4 s\n",
      "Wall time: 10.7 s\n",
      "***\n",
      "On testing dataset, classifier nDCG mean score is 0.823896.\n"
     ]
    }
   ],
   "source": [
    "# Calculate nDCG mean score on testing dataset:\n",
    "print(\"Time info about nDCG mean score calculation on testing dataset:\")\n",
    "%time ndcg_mean_score = ndcg_mean_score_calc(ootb_mlp_clf, X_test, y_test)\n",
    "print(\"***\")\n",
    "print(\"On testing dataset, classifier nDCG mean score is {:.6f}.\".format(ndcg_mean_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time info about nDCG mean score calculation for each class on testing dataset:\n",
      "CPU times: user 20.7 s, sys: 308 ms, total: 21 s\n",
      "Wall time: 10.5 s\n",
      "***\n",
      "Detailed results for each class on testing dataset:\n",
      "nDCG mean score for AU: 0.000000\n",
      "nDCG mean score for CA: 0.000000\n",
      "nDCG mean score for DE: 0.000000\n",
      "nDCG mean score for ES: 0.000000\n",
      "nDCG mean score for FR: 0.430677\n",
      "nDCG mean score for GB: 0.029950\n",
      "nDCG mean score for IT: 0.358879\n",
      "nDCG mean score for NDF: 0.949682\n",
      "nDCG mean score for NL: 0.000000\n",
      "nDCG mean score for PT: 0.000000\n",
      "nDCG mean score for US: 0.790185\n",
      "nDCG mean score for other: 0.500000\n"
     ]
    }
   ],
   "source": [
    "# Calculate nDCG mean score for each class on testing dataset:\n",
    "print(\"Time info about nDCG mean score calculation for each class on testing dataset:\")\n",
    "%time ndcg_mean_scores_list = detailed_ndcg_mean_score_calc(ootb_mlp_clf, X_test, y_test, encoding_dict)\n",
    "print(\"***\")\n",
    "print(\"Detailed results for each class on testing dataset:\")\n",
    "for country_dest in range(12):\n",
    "    print(\"nDCG mean score for {}: {:.6f}\".format(decoding_dict[country_dest],\n",
    "                                                  ndcg_mean_scores_list[country_dest]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../models/ootb_mlp_clf.pkl']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save model:\n",
    "joblib.dump(ootb_mlp_clf, \"../models/ootb_mlp_clf.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \"Optimized\" multi-layer perceptron classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time info about randomized search cross validation:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/envs/airbnb/lib/python3.7/site-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 4s, sys: 8.34 s, total: 3min 13s\n",
      "Wall time: 20min 28s\n"
     ]
    }
   ],
   "source": [
    "# Set parameters of the random grid:\n",
    "hidden_layer_sizes = [(100), (110, 60), (80, 40, 20), (120, 60, 30)]\n",
    "activation = ['identity', 'logistic', 'tanh', 'relu']\n",
    "solver = ['adam']\n",
    "learning_rate_init = [0.1, 0.01, 0.001, 0.0001, 0.00001]\n",
    "max_iter = [200]\n",
    "random_state = [42]\n",
    "early_stopping = [True]\n",
    "validation_fraction = [0.2]\n",
    "n_iter_no_change = [10]\n",
    "\n",
    "# Create the random grid:\n",
    "random_grid = {'hidden_layer_sizes': hidden_layer_sizes,\n",
    "               'activation': activation,\n",
    "               'solver': solver,\n",
    "               'learning_rate_init': learning_rate_init,\n",
    "               'max_iter': max_iter,\n",
    "               'random_state': random_state,\n",
    "               'early_stopping': early_stopping,\n",
    "               'validation_fraction': validation_fraction,\n",
    "               'n_iter_no_change': n_iter_no_change}\n",
    "\n",
    "# Perform randomized search cross validation:\n",
    "\n",
    "mlp_clf = MLPClassifier()\n",
    "\n",
    "mlp_clf_random = RandomizedSearchCV(estimator=mlp_clf,\n",
    "                                    param_distributions=random_grid,\n",
    "                                    n_iter=20,\n",
    "                                    n_jobs=-1,\n",
    "                                    random_state=42,\n",
    "                                    verbose=0)\n",
    "\n",
    "print(\"Time info about randomized search cross validation:\")\n",
    "%time mlp_clf_fit = mlp_clf_random.fit(X_train, y_train)\n",
    "\n",
    "# Get the \"best\" classifier:\n",
    "opt_mlp_clf = mlp_clf_fit.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Parameters of the 'best' classifier:\n",
      "- Paramater validation_fraction: 0.2\n",
      "- Paramater solver: adam\n",
      "- Paramater random_state: 42\n",
      "- Paramater n_iter_no_change: 10\n",
      "- Paramater max_iter: 200\n",
      "- Paramater learning_rate_init: 0.0001\n",
      "- Paramater hidden_layer_sizes: (80, 40, 20)\n",
      "- Paramater early_stopping: True\n",
      "- Paramater activation: relu\n"
     ]
    }
   ],
   "source": [
    "# Parameters of the \"best\" classifier:\n",
    "print(\"*** Parameters of the 'best' classifier:\")\n",
    "for param, param_value in mlp_clf_fit.best_params_.items():\n",
    "    print(\"- Paramater {}: {}\".format(param, param_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time info about classifier prediction:\n",
      "CPU times: user 1.6 ms, sys: 307 Âµs, total: 1.91 ms\n",
      "Wall time: 1.03 ms\n",
      "***\n",
      "For the classifier check:\n",
      "- Real first booking destination country: US\n",
      "- Predictions list: ['US', 'NDF', 'other', 'FR', 'ES', 'IT', 'GB', 'DE', 'CA', 'NL', 'AU', 'PT']\n"
     ]
    }
   ],
   "source": [
    "# Perform one prediction to check classifier:\n",
    "print(\"Time info about classifier prediction:\")\n",
    "%time preds_list = clf_prediction(opt_mlp_clf, X_train[0])\n",
    "print(\"***\")\n",
    "\n",
    "# Reverse encoding dictionary:\n",
    "decoding_dict = dict(map(reversed, encoding_dict.items()))\n",
    "\n",
    "# Print result:\n",
    "print(\"For the classifier check:\")\n",
    "print(\"- Real first booking destination country: {}\".format(decoding_dict[y_train[0]]))\n",
    "print(\"- Predictions list: {}\".format([decoding_dict[x] for x in preds_list]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time info about nDCG mean score calculation on training dataset:\n",
      "CPU times: user 1min 21s, sys: 1.36 s, total: 1min 23s\n",
      "Wall time: 41.6 s\n",
      "***\n",
      "On training dataset, classifier nDCG mean score is 0.822968.\n"
     ]
    }
   ],
   "source": [
    "# Calculate nDCG mean score on training dataset:\n",
    "print(\"Time info about nDCG mean score calculation on training dataset:\")\n",
    "%time ndcg_mean_score = ndcg_mean_score_calc(opt_mlp_clf, X_train, y_train)\n",
    "print(\"***\")\n",
    "print(\"On training dataset, classifier nDCG mean score is {:.6f}.\".format(ndcg_mean_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time info about nDCG mean score calculation on testing dataset:\n",
      "CPU times: user 21 s, sys: 454 ms, total: 21.5 s\n",
      "Wall time: 11 s\n",
      "***\n",
      "On testing dataset, classifier nDCG mean score is 0.822270.\n"
     ]
    }
   ],
   "source": [
    "# Calculate nDCG mean score on testing dataset:\n",
    "print(\"Time info about nDCG mean score calculation on testing dataset:\")\n",
    "%time ndcg_mean_score = ndcg_mean_score_calc(opt_mlp_clf, X_test, y_test)\n",
    "print(\"***\")\n",
    "print(\"On testing dataset, classifier nDCG mean score is {:.6f}.\".format(ndcg_mean_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time info about nDCG mean score calculation for each class on testing dataset:\n",
      "CPU times: user 20.4 s, sys: 337 ms, total: 20.7 s\n",
      "Wall time: 10.4 s\n",
      "***\n",
      "Detailed results for each class on testing dataset:\n",
      "nDCG mean score for AU: 0.000000\n",
      "nDCG mean score for CA: 0.000000\n",
      "nDCG mean score for DE: 0.000000\n",
      "nDCG mean score for ES: 0.413072\n",
      "nDCG mean score for FR: 0.411407\n",
      "nDCG mean score for GB: 0.000832\n",
      "nDCG mean score for IT: 0.010234\n",
      "nDCG mean score for NDF: 0.935384\n",
      "nDCG mean score for NL: 0.000000\n",
      "nDCG mean score for PT: 0.000000\n",
      "nDCG mean score for US: 0.818191\n",
      "nDCG mean score for other: 0.491116\n"
     ]
    }
   ],
   "source": [
    "# Calculate nDCG mean score for each class on testing dataset:\n",
    "print(\"Time info about nDCG mean score calculation for each class on testing dataset:\")\n",
    "%time ndcg_mean_scores_list = detailed_ndcg_mean_score_calc(opt_mlp_clf, X_test, y_test, encoding_dict)\n",
    "print(\"***\")\n",
    "print(\"Detailed results for each class on testing dataset:\")\n",
    "for country_dest in range(12):\n",
    "    print(\"nDCG mean score for {}: {:.6f}\".format(decoding_dict[country_dest],\n",
    "                                                  ndcg_mean_scores_list[country_dest]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../models/opt_mlp_clf.pkl']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save model:\n",
    "joblib.dump(opt_mlp_clf, \"../models/opt_mlp_clf.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "As a quick conclusion, for the results obtained for the last \"optimized\" multi-layer perceptron classifier, we can note 4 major elements:\n",
    "* On testing dataset, it gets a better nDCG mean score than the one obtained by the naive model.\n",
    "* On testing dataset, it gets better nDCG mean scores for predicting correctly Spain, Great Britain and USA than the ones obtained by the naive model.\n",
    "* On testing dataset, it gets worse nDCG mean scores for predicting correctly France, Italy, no destination found and other than the ones obtained by the naive model.\n",
    "* On testing dataset, it is as \"bad\" as the naive model for predicting correctly Australia, Canada, Germany, Netherlands and Portugal."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
