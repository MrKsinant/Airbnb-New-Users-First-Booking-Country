{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Corrected Voting Classifier\n",
    "---\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Here, we are going to try tackling the current problem using an **corrected voting classifier**.\n",
    "\n",
    "This attempt will consist on two steps:\n",
    "* A first step where we are going to exploit the voting classifier we have trained previously, to provide us predictions on first booking destination country for a given sample data.\n",
    "* A second step with the aim to correct the predictions made during the first step: For this step, we are going to use a gradient boosting classifier.\n",
    "\n",
    "As always, the prerequisite step consists on loading the appropriate packages to perform our work:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activate 'airbnb' environment:\n",
    "!source activate airbnb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/envs/airbnb/lib/python3.7/site-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# Needed packages:\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.externals import joblib\n",
    "from utils import (create_training_testing_datasets,\n",
    "                   calculate_dcg,\n",
    "                   calculate_ndcg,\n",
    "                   clf_prediction,\n",
    "                   ndcg_mean_score_calc,\n",
    "                   detailed_ndcg_mean_score_calc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Create training and testing datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Some basic info:\n",
      "'consolidated_dataset' has 213451 data points with 161 variables each.\n",
      "'consolidated_dataset' counts 0 missing values.\n",
      "\n",
      "*** First lines:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>country_destination</th>\n",
       "      <th>nans</th>\n",
       "      <th>day_account_created</th>\n",
       "      <th>weekday_account_created</th>\n",
       "      <th>week_account_created</th>\n",
       "      <th>month_account_created</th>\n",
       "      <th>year_account_created</th>\n",
       "      <th>day_first_active</th>\n",
       "      <th>weekday_first_active</th>\n",
       "      <th>...</th>\n",
       "      <th>first_browser_SeaMonkey</th>\n",
       "      <th>first_browser_Silk</th>\n",
       "      <th>first_browser_SiteKiosk</th>\n",
       "      <th>first_browser_SlimBrowser</th>\n",
       "      <th>first_browser_Sogou Explorer</th>\n",
       "      <th>first_browser_Stainless</th>\n",
       "      <th>first_browser_TenFourFox</th>\n",
       "      <th>first_browser_TheWorld Browser</th>\n",
       "      <th>first_browser_Yandex.Browser</th>\n",
       "      <th>first_browser_wOSBrowser</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>NDF</td>\n",
       "      <td>1.225078</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>6</td>\n",
       "      <td>2010</td>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38.0</td>\n",
       "      <td>NDF</td>\n",
       "      <td>-0.453135</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>5</td>\n",
       "      <td>2011</td>\n",
       "      <td>23</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>56.0</td>\n",
       "      <td>US</td>\n",
       "      <td>-0.453135</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>9</td>\n",
       "      <td>2010</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>42.0</td>\n",
       "      <td>other</td>\n",
       "      <td>-0.453135</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>12</td>\n",
       "      <td>2011</td>\n",
       "      <td>31</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41.0</td>\n",
       "      <td>US</td>\n",
       "      <td>0.385972</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>9</td>\n",
       "      <td>2010</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 161 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    age country_destination      nans  day_account_created  \\\n",
       "0  -1.0                 NDF  1.225078                   28   \n",
       "1  38.0                 NDF -0.453135                   25   \n",
       "2  56.0                  US -0.453135                   28   \n",
       "3  42.0               other -0.453135                    5   \n",
       "4  41.0                  US  0.385972                   14   \n",
       "\n",
       "   weekday_account_created  week_account_created  month_account_created  \\\n",
       "0                        0                    26                      6   \n",
       "1                        2                    21                      5   \n",
       "2                        1                    39                      9   \n",
       "3                        0                    49                     12   \n",
       "4                        1                    37                      9   \n",
       "\n",
       "   year_account_created  day_first_active  weekday_first_active  ...  \\\n",
       "0                  2010                19                     3  ...   \n",
       "1                  2011                23                     5  ...   \n",
       "2                  2010                 9                     1  ...   \n",
       "3                  2011                31                     5  ...   \n",
       "4                  2010                 8                     1  ...   \n",
       "\n",
       "   first_browser_SeaMonkey  first_browser_Silk  first_browser_SiteKiosk  \\\n",
       "0                        0                   0                        0   \n",
       "1                        0                   0                        0   \n",
       "2                        0                   0                        0   \n",
       "3                        0                   0                        0   \n",
       "4                        0                   0                        0   \n",
       "\n",
       "   first_browser_SlimBrowser  first_browser_Sogou Explorer  \\\n",
       "0                          0                             0   \n",
       "1                          0                             0   \n",
       "2                          0                             0   \n",
       "3                          0                             0   \n",
       "4                          0                             0   \n",
       "\n",
       "   first_browser_Stainless  first_browser_TenFourFox  \\\n",
       "0                        0                         0   \n",
       "1                        0                         0   \n",
       "2                        0                         0   \n",
       "3                        0                         0   \n",
       "4                        0                         0   \n",
       "\n",
       "   first_browser_TheWorld Browser  first_browser_Yandex.Browser  \\\n",
       "0                               0                             0   \n",
       "1                               0                             0   \n",
       "2                               0                             0   \n",
       "3                               0                             0   \n",
       "4                               0                             0   \n",
       "\n",
       "   first_browser_wOSBrowser  \n",
       "0                         0  \n",
       "1                         0  \n",
       "2                         0  \n",
       "3                         0  \n",
       "4                         0  \n",
       "\n",
       "[5 rows x 161 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the data:\n",
    "consolidated_dataset = pd.read_csv(\"../data/consolidated_dataset.csv\")\n",
    "\n",
    "# Check basic info:\n",
    "print(\"*** Some basic info:\")\n",
    "print(\"'consolidated_dataset' has {} data points with {} variables each.\".format(*consolidated_dataset.shape))\n",
    "print(\"'consolidated_dataset' counts {} missing values.\".format(consolidated_dataset.isnull().sum().sum()))\n",
    "\n",
    "# Give a look to the first lines:\n",
    "print(\"\\n*** First lines:\")\n",
    "display(consolidated_dataset.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training and testing datasets:\n",
    "X_train, X_test, y_train, y_test, encoding_dict = create_training_testing_datasets(consolidated_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Train a gradient boosting classifier on predictions of previous voting classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load previous voting classifier:\n",
    "ootb_voting_clf = joblib.load(\"../models/ootb_voting_clf.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time info about classifier prediction:\n",
      "CPU times: user 34.3 ms, sys: 22.1 ms, total: 56.4 ms\n",
      "Wall time: 568 ms\n",
      "***\n",
      "For the classifier check:\n",
      "- Real first booking destination country: US\n",
      "- Predictions list: ['US', 'NDF', 'other', 'FR', 'ES', 'IT', 'GB', 'CA', 'DE', 'NL', 'AU', 'PT']\n"
     ]
    }
   ],
   "source": [
    "# Perform one prediction to check classifier:\n",
    "print(\"Time info about classifier prediction:\")\n",
    "%time preds_list = clf_prediction(ootb_voting_clf, X_train[0])\n",
    "print(\"***\")\n",
    "\n",
    "# Reverse encoding dictionary:\n",
    "decoding_dict = dict(map(reversed, encoding_dict.items()))\n",
    "\n",
    "# Print result:\n",
    "print(\"For the classifier check:\")\n",
    "print(\"- Real first booking destination country: {}\".format(decoding_dict[y_train[0]]))\n",
    "print(\"- Predictions list: {}\".format([decoding_dict[x] for x in preds_list]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate training dataset for new gradient boosting classifier:\n",
    "X_pred_probs_train = []\n",
    "for i in range(len(y_train)):\n",
    "    pred_probs = ootb_voting_clf.predict_proba(X_train[i].reshape(1, -1)).tolist()[0]\n",
    "    X_pred_probs_train.append(pred_probs)\n",
    "X_pred_probs_train = np.array(X_pred_probs_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time info about classifier training:\n",
      "CPU times: user 12min 37s, sys: 32.7 s, total: 13min 9s\n",
      "Wall time: 8min 31s\n"
     ]
    }
   ],
   "source": [
    "# Initialize the new gradient boosting classifier:\n",
    "gb_clf = GradientBoostingClassifier(random_state=42)\n",
    "\n",
    "# Train the classifier:\n",
    "print(\"Time info about classifier training:\")\n",
    "%time corr_gb_clf = gb_clf.fit(X_pred_probs_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean accuracy on training dataset of 'corr_gb_clf' is: 0.885037\n"
     ]
    }
   ],
   "source": [
    "# Check mean accuracy on training dataset:\n",
    "mean_accuracy = corr_gb_clf.score(X_pred_probs_train, y_train)\n",
    "print(\"The mean accuracy on training dataset of 'corr_gb_clf' is: {:.6f}\".format(mean_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../models/corr_gb_clf.pkl']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save model:\n",
    "joblib.dump(corr_gb_clf, \"../models/corr_gb_clf.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Build a corrected voting classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build prediction mechanism of enhanced gradient boosting classifier:\n",
    "\n",
    "def corr_voting_clf_prediction(clf_1, clf_2, sample_data):\n",
    "    \"\"\" Perform predictions thanks to enhanced gradient boosting classifier \"\"\"\n",
    "    \n",
    "    # Perform predictions with first level classifier:\n",
    "    pred_probs_1 = clf_1.predict_proba(sample_data.reshape(1, -1)).tolist()[0]\n",
    "    pred_probs_1 = np.array(pred_probs_1)\n",
    "    \n",
    "    # Perform predictions with second level classifier:\n",
    "    pred_probs_2 = clf_2.predict_proba(pred_probs_1.reshape(1, -1)).tolist()[0]\n",
    "    \n",
    "    # Build predictive ordered list of first booking destination country:\n",
    "    preds_list = [x[1] for x in sorted(zip(pred_probs_2, range(12)), reverse=True) if x[0] != 0.]\n",
    "    \n",
    "    # Return result:\n",
    "    return preds_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time info about classifier prediction:\n",
      "CPU times: user 14.1 ms, sys: 1.99 ms, total: 16.1 ms\n",
      "Wall time: 13.2 ms\n",
      "***\n",
      "For the classifier check:\n",
      "- Real first booking destination country: US\n",
      "- Predictions list: ['US', 'other', 'NDF', 'FR', 'IT', 'GB', 'ES', 'CA', 'DE', 'AU', 'PT', 'NL']\n"
     ]
    }
   ],
   "source": [
    "# Perform one prediction to check classifier:\n",
    "print(\"Time info about classifier prediction:\")\n",
    "%time preds_list = corr_voting_clf_prediction(ootb_voting_clf, corr_gb_clf, X_train[0])\n",
    "print(\"***\")\n",
    "\n",
    "# Print result:\n",
    "print(\"For the classifier check:\")\n",
    "print(\"- Real first booking destination country: {}\".format(decoding_dict[y_train[0]]))\n",
    "print(\"- Predictions list: {}\".format([decoding_dict[x] for x in preds_list]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapt nDCG mean score calculators:\n",
    "\n",
    "def ndcg_mean_score_calc_2(clf_1, clf_2, X, y):\n",
    "    \"\"\" Calculate nDCG mean score on a labeled dataset \"\"\"\n",
    "    \n",
    "    # Set nDCG scores list:\n",
    "    ndcg_scores_list = []\n",
    "    \n",
    "    # Loop on labeled dataset:\n",
    "    for i in range(len(y)):\n",
    "        ndcg_score = calculate_ndcg(corr_voting_clf_prediction(clf_1, clf_2, X[i]), y[i])\n",
    "        ndcg_scores_list.append(ndcg_score)\n",
    "        \n",
    "    # Determine nDCG mean score:\n",
    "    ndcg_mean_score = np.mean(ndcg_scores_list)\n",
    "    \n",
    "    # Return result:\n",
    "    return ndcg_mean_score\n",
    "\n",
    "def detailed_ndcg_mean_score_calc_2(clf_1, clf_2, X, y, encoding_dict):\n",
    "    \"\"\" Calculate nDCG mean score on a labeled dataset for each class \"\"\"\n",
    "    \n",
    "    # Reverse encoding dictionary:\n",
    "    decoding_dict = dict(map(reversed, encoding_dict.items()))\n",
    "    \n",
    "    # Set nDCG scores objects:\n",
    "    ndcg_scores_dict = {country_dest: [] for country_dest in range(12)}\n",
    "    ndcg_mean_scores_list = []\n",
    "    \n",
    "    # Loop on labeled dataset:\n",
    "    for i in range(len(y)):\n",
    "        ndcg_score = calculate_ndcg(corr_voting_clf_prediction(clf_1, clf_2, X[i]), y[i])\n",
    "        ndcg_scores_dict[y[i]].append(ndcg_score)\n",
    "        \n",
    "    # Loop on country destinations:\n",
    "    for country_dest in range(12):\n",
    "        ndcg_mean_scores_list.append(np.mean(ndcg_scores_dict[country_dest]))\n",
    "        \n",
    "    # Return result:\n",
    "    return ndcg_mean_scores_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time info about nDCG mean score calculation on training dataset:\n",
      "CPU times: user 50min 44s, sys: 53.1 s, total: 51min 37s\n",
      "Wall time: 25min 50s\n",
      "***\n",
      "On training dataset, classifier nDCG mean score is 0.951813.\n"
     ]
    }
   ],
   "source": [
    "# Calculate nDCG mean score on training dataset:\n",
    "print(\"Time info about nDCG mean score calculation on training dataset:\")\n",
    "%time ndcg_mean_score = ndcg_mean_score_calc_2(ootb_voting_clf, corr_gb_clf, X_train, y_train)\n",
    "print(\"***\")\n",
    "print(\"On training dataset, classifier nDCG mean score is {:.6f}.\".format(ndcg_mean_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time info about nDCG mean score calculation on testing dataset:\n",
      "CPU times: user 12min 42s, sys: 13.5 s, total: 12min 55s\n",
      "Wall time: 6min 28s\n",
      "***\n",
      "On testing dataset, classifier nDCG mean score is 0.780407.\n"
     ]
    }
   ],
   "source": [
    "# Calculate nDCG mean score on testing dataset:\n",
    "print(\"Time info about nDCG mean score calculation on testing dataset:\")\n",
    "%time ndcg_mean_score = ndcg_mean_score_calc_2(ootb_voting_clf, corr_gb_clf, X_test, y_test)\n",
    "print(\"***\")\n",
    "print(\"On testing dataset, classifier nDCG mean score is {:.6f}.\".format(ndcg_mean_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time info about nDCG mean score calculation for each class on testing dataset:\n",
      "CPU times: user 12min 44s, sys: 13.5 s, total: 12min 57s\n",
      "Wall time: 6min 29s\n",
      "***\n",
      "Detailed results for each class on testing dataset:\n",
      "nDCG mean score for AU: 0.059779\n",
      "nDCG mean score for CA: 0.078116\n",
      "nDCG mean score for DE: 0.100146\n",
      "nDCG mean score for ES: 0.231286\n",
      "nDCG mean score for FR: 0.386274\n",
      "nDCG mean score for GB: 0.125668\n",
      "nDCG mean score for IT: 0.136344\n",
      "nDCG mean score for NDF: 0.887426\n",
      "nDCG mean score for NL: 0.041941\n",
      "nDCG mean score for PT: 0.000000\n",
      "nDCG mean score for US: 0.772363\n",
      "nDCG mean score for other: 0.441702\n"
     ]
    }
   ],
   "source": [
    "# Calculate nDCG mean score for each class on testing dataset:\n",
    "print(\"Time info about nDCG mean score calculation for each class on testing dataset:\")\n",
    "%time ndcg_mean_scores_list = detailed_ndcg_mean_score_calc_2(ootb_voting_clf, corr_gb_clf, X_test, y_test, encoding_dict)\n",
    "print(\"***\")\n",
    "print(\"Detailed results for each class on testing dataset:\")\n",
    "for country_dest in range(12):\n",
    "    print(\"nDCG mean score for {}: {:.6f}\".format(decoding_dict[country_dest],\n",
    "                                                  ndcg_mean_scores_list[country_dest]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "As a quick conclusion, for the results obtained for this corrected voting classifier, we can note 4 major elements in comparison with the gradient boosting classifier we have built previously (the one which reached the best results):\n",
    "* On testing dataset, it gets a (significantly) worse nDCG mean score than the one obtained by the gradient boosting classifier.\n",
    "* On testing dataset, it gets better nDCG mean scores for predicting correctly Australia, Canada, Germany, Great Britain and Netherlands than the ones obtained by the gradient boosting classifier.\n",
    "* On testing dataset, it gets worse nDCG mean scores for predicting correctly Spain, France, Italy, no destination found, USA and other than the ones obtained by the gradient boosting classifier.\n",
    "* On testing dataset, it is as \"bad\" as the gradient boosting classifier for predicting correctly Portugal."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
